{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The code is based on the paper: Towards Simulating Foggy and Hazy Images and Evaluating Their Authenticity.\n",
    "Referenced Github: https://github.com/noahzn/FoHIS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.special import gamma"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:19:18.523782Z",
     "start_time": "2024-05-09T16:19:18.516453Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "BLOCK_SIZE_ROW     = 48\n",
    "BLOCK_SIZE_COL     = 48\n",
    "NORMALIZED_WIDTH   = 528\n",
    "FEATURE_NUMBER     = 16\n",
    "GRADIENT_THRESHOLD_L = 3\n",
    "GRADIENT_THRESHOLD_R = 60\n",
    "DARK_CHANNEL_THRESHOLD_L = 30\n",
    "DARK_CHANNEL_THRESHOLD_R = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:19:19.239213Z",
     "start_time": "2024-05-09T16:19:19.236236Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def filter2d(input_img, filter, frame):\n",
    "    size = len(input_img), len(input_img[0])\n",
    "    output = []\n",
    "    for i in range(size[0]):\n",
    "        temp = []\n",
    "        for j in range(size[1]):\n",
    "            temp.append(filter(input_img, (i, j), frame))\n",
    "        output.append(temp)\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:19:19.741449Z",
     "start_time": "2024-05-09T16:19:19.733584Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def getDark(input_img, filter, frame):\n",
    "    size = input_img.size\n",
    "    output = []\n",
    "\n",
    "    for x in range(size[1]):\n",
    "        temp = []\n",
    "        for y in range(size[0]):\n",
    "            temp.append(min(input_img.getpixel((y, x))))\n",
    "\n",
    "        output.append(temp)\n",
    "\n",
    "    output = filter2d(output, filter, frame)\n",
    "\n",
    "    output_img = Image.new('L', size)\n",
    "\n",
    "    for x in range(size[1]):\n",
    "        for y in range(size[0]):\n",
    "            output_img.putpixel((y, x), output[x][y])\n",
    "\n",
    "    return output_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:19:20.177643Z",
     "start_time": "2024-05-09T16:19:20.174115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def minimizeFilter(input_img, point, size):\n",
    "    begin = (point[0] - size[0] / 2, point[0] + size[0] / 2 + 1)\n",
    "    end = (point[1] - size[1] / 2, point[1] + size[1] / 2 + 1)\n",
    "    begin1, begin2 = int(begin[0]), int(begin[1])\n",
    "    end1, end2 = int(end[0]), int(end[1])\n",
    "    l = []\n",
    "    for i in range(begin1, begin2):\n",
    "        for j in range(end1, end2):\n",
    "            if (i >= 0 and i < len(input_img)) and (j >= 0 and j < len(input_img[0])):\n",
    "                l.append(input_img[i][j])\n",
    "    return min(l)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:19:20.965408Z",
     "start_time": "2024-05-09T16:19:20.958091Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def estimate_aggd_parameter(vec):\n",
    "    vec = np.nan_to_num(vec)\n",
    "    # print(vec)\n",
    "    gam = [x/1000 for x in range(200, 10001, 1)]\n",
    "    r_gam = [(gamma(2/x)**2/(gamma(1/x)*gamma(3/x))) for x in gam]\n",
    "    leftstd = np.nan_to_num(np.sqrt(np.mean(vec[vec < 0]**2)))\n",
    "    rightstd = np.nan_to_num(np.sqrt(np.mean(vec[vec > 0]**2)))\n",
    "    gammahat = np.nan_to_num(leftstd / (rightstd+0.00001))\n",
    "    rhat = np.nan_to_num((np.mean(np.abs(vec))**2) / np.nanmean(vec**2))\n",
    "    rhatnorm = (rhat*(gammahat**3 + 1)*(gammahat + 1))/((gammahat**2 + 1)**2)\n",
    "    m1 = (r_gam - rhatnorm)**2\n",
    "    m2 = m1.tolist()\n",
    "    array_position = m2.index(np.min(m1))\n",
    "    alpha = gam[array_position]\n",
    "    beta_l = leftstd * np.sqrt(gamma(1/alpha)/gamma(3/alpha))\n",
    "    beta_r = rightstd * np.sqrt(gamma(1/alpha)/gamma(3/alpha))\n",
    "    return alpha, beta_l, beta_r"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:19:21.526180Z",
     "start_time": "2024-05-09T16:19:21.523392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def compute_features(gray, gradient):\n",
    "    features = []\n",
    "    for m in [gray]:\n",
    "        μ = cv2.GaussianBlur(m, (5, 5), 5/6, borderType=cv2.BORDER_REPLICATE)\n",
    "        σ = np.sqrt(abs(cv2.GaussianBlur(m*m, (5, 5), 5/6, borderType=cv2.BORDER_REPLICATE) - μ*μ))\n",
    "        I = (m - μ) / (σ + 1)\n",
    "        alpha, beta_l, beta_r = estimate_aggd_parameter(I)\n",
    "        features.append(alpha)\n",
    "        features.append((beta_l+beta_r)/2)\n",
    "        I = np.log(I + 0.0001)\n",
    "        shift1 = [(0, 1), (1, 0), (1, 1), (1, -1)]\n",
    "        shift2 = [(-1, 0), (1, 0), (0, -1), (0, 1), (0, 0), (1, 1), (0, 1), (1, 0), (-1, -1), (1, 1), (-1, 1), (1, -1)]\n",
    "        for i in shift1:\n",
    "            D = np.roll(I, i, axis=(0, 1)) - I\n",
    "            alpha, beta_l, beta_r = estimate_aggd_parameter(D)\n",
    "            features.append(alpha)\n",
    "            features.append((beta_l+beta_r)/2)\n",
    "\n",
    "        for i in range(3):\n",
    "            D = np.roll(I, shift2[4*i], axis=(0, 1)) + np.roll(I, shift2[4*i+1], axis=(0, 1)) \\\n",
    "                - np.roll(I, shift2[4*i+2], axis=(0, 1)) - np.roll(I, shift2[4*i+3], axis=(0, 1))\n",
    "            alpha, beta_l, beta_r = estimate_aggd_parameter(D)\n",
    "\n",
    "            features.append(alpha)\n",
    "            features.append((beta_l+beta_r)/2)\n",
    "\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:19:22.078428Z",
     "start_time": "2024-05-09T16:19:22.073601Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def authenticity(img):\n",
    "    data = sio.loadmat('Shift&Dense-Dataset-1.mat')\n",
    "    mu_prisparam1 = data['mu1']\n",
    "    mu_prisparam2 = data['mu2']\n",
    "    cov_prisparam1 = data['cov1']\n",
    "    cov_prisparam2 = data['cov2']\n",
    "\n",
    "    img = cv2.resize(cv2.imread(img), (NORMALIZED_WIDTH, NORMALIZED_WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    block_rownum = math.floor(gray.shape[0] / BLOCK_SIZE_ROW)\n",
    "    block_colnum = math.floor(gray.shape[1] / BLOCK_SIZE_COL)\n",
    "    img = img[:block_rownum * BLOCK_SIZE_ROW, :block_colnum * BLOCK_SIZE_COL, :]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)[:, :, 0]\n",
    "\n",
    "    # gradient magnitude\n",
    "    gradx = cv2.Sobel(gray, cv2.CV_16S, 1, 0, ksize=3)\n",
    "    grady = cv2.Sobel(gray, cv2.CV_16S, 0, 1, ksize=3)\n",
    "    absX = cv2.convertScaleAbs(gradx)\n",
    "    absY = cv2.convertScaleAbs(grady)\n",
    "    gradient = cv2.addWeighted(absX, 0.5, absY, 0.5, 0)\n",
    "    gradient2 = gradient\n",
    "    gradient2[gradient2 < 20] = 0\n",
    "    gradient2[gradient2 >= 20] = 255\n",
    "\n",
    "    # dark channel\n",
    "    dark_image = np.asarray(getDark(Image.fromarray(np.uint8(img)), minimizeFilter, (10, 10)))\n",
    "\n",
    "    quality = []\n",
    "    features1_list_all = []\n",
    "    features2_list_all = []\n",
    "    for i in range(block_rownum):\n",
    "        for j in range(block_colnum):\n",
    "            features1_list = []\n",
    "            features2_list = []\n",
    "            crop_row_start = i * BLOCK_SIZE_ROW\n",
    "            crop_row_end = (i + 1) * BLOCK_SIZE_ROW\n",
    "            crop_col_start = j * BLOCK_SIZE_COL\n",
    "            crop_col_end = (j + 1) * BLOCK_SIZE_COL\n",
    "\n",
    "            crop_gray = gray[crop_row_start: crop_row_end, crop_col_start:crop_col_end]\n",
    "            crop_img = img[crop_row_start: crop_row_end, crop_col_start:crop_col_end]\n",
    "            crop_gradient = gradient[crop_row_start: crop_row_end, crop_col_start:crop_col_end]\n",
    "            crop_gradient2 = gradient2[crop_row_start: crop_row_end, crop_col_start:crop_col_end]\n",
    "            crop_dark_image = dark_image[crop_row_start: crop_row_end, crop_col_start:crop_col_end]\n",
    "\n",
    "            if np.mean(crop_dark_image) < DARK_CHANNEL_THRESHOLD_L:\n",
    "                if np.count_nonzero(crop_gradient2) > 400:\n",
    "                    features1_list.extend(\n",
    "                        compute_features(crop_gray.astype(np.float64), crop_gradient.astype(np.float64)))\n",
    "                    cv2.rectangle(img, (crop_col_start, crop_row_start), (crop_col_end, crop_row_end),\n",
    "                                  (0, 255, 0))\n",
    "                else:\n",
    "                    features1_list.extend(\n",
    "                        compute_features(crop_gray.astype(np.float64), crop_gradient.astype(np.float64)))\n",
    "                    cv2.rectangle(img, (crop_col_start, crop_row_start), (crop_col_end, crop_row_end),\n",
    "                                  (255, 0, 0))\n",
    "\n",
    "            elif np.mean(crop_dark_image) >= DARK_CHANNEL_THRESHOLD_L:\n",
    "                features2_list.extend(\n",
    "                    compute_features(crop_gray.astype(np.float64), crop_gradient.astype(np.float64)))\n",
    "                cv2.rectangle(img, (crop_col_start, crop_row_start), (crop_col_end, crop_row_end),\n",
    "                              (255, 0, 255))\n",
    "\n",
    "            features1_list_all.extend(features1_list)\n",
    "            features2_list_all.extend(features2_list)\n",
    "\n",
    "    if len(features1_list_all) != 0:\n",
    "        features1 = np.array(features1_list_all).reshape((int(len(features1_list_all) / FEATURE_NUMBER)), FEATURE_NUMBER)\n",
    "        if features1.shape[0] > 1:\n",
    "            mu_distparam1 = (np.mean(features1, axis=0))\n",
    "            cov_distparam1 = np.cov(features1.reshape(features1.shape[1], features1.shape[0]))\n",
    "            invcov_param1 = np.linalg.inv((cov_prisparam1 + cov_distparam1) / 2)\n",
    "            q1 = np.sqrt(\n",
    "                np.dot(np.dot((mu_prisparam1 - mu_distparam1), invcov_param1), np.transpose(mu_prisparam1 - mu_distparam1)))\n",
    "            quality.append(np.nanmean(q1))\n",
    "        else:\n",
    "            features2_list_all.extend(features2_list_all)\n",
    "\n",
    "    if len(features2_list_all) != 0:\n",
    "        features2 = np.array(features2_list_all).reshape((int(len(features2_list_all) / FEATURE_NUMBER)), FEATURE_NUMBER)\n",
    "        # input(features2)\n",
    "        mu_distparam2 = (np.mean(features2, axis=0))\n",
    "        cov_distparam2 = np.cov(features2.reshape(features2.shape[1], features2.shape[0]))\n",
    "\n",
    "        # input(mu_distparam2)\n",
    "        invcov_param2 = np.linalg.inv((cov_prisparam2 + cov_distparam2) / 2)\n",
    "        q2 = np.sqrt(\n",
    "            np.dot(np.dot((mu_prisparam2 - mu_distparam2), invcov_param2), np.transpose(mu_prisparam2 - mu_distparam2)))\n",
    "\n",
    "        # input(q2)\n",
    "        quality.append(np.nanmean(q2))\n",
    "    return quality\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:19:23.108272Z",
     "start_time": "2024-05-09T16:19:23.089665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/c2j4rkjd52z6m0m84r33nr7r0000gn/T/ipykernel_19333/3702971359.py:10: RuntimeWarning: invalid value encountered in log\n",
      "  I = np.log(I + 0.0001)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[2.990390269819463, 5.97826601781121]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authenticity('../Fog_Simulator-FoHIS/Results/Shift_Images/image_0c3b-b343_00000000_img_front.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T16:19:40.041187Z",
     "start_time": "2024-05-09T16:19:24.373163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/c2j4rkjd52z6m0m84r33nr7r0000gn/T/ipykernel_19333/3702971359.py:10: RuntimeWarning: invalid value encountered in log\n",
      "  I = np.log(I + 0.0001)\n"
     ]
    }
   ],
   "source": [
    "def process_images_in_folder(folder_path):\n",
    "    results = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            result = authenticity(image_path)\n",
    "            results.append((image_path, result))\n",
    "    return results\n",
    "\n",
    "folders = ['../Fog_Simulator-FoHIS/Results/With_Depth_Maps', '../Fog_Simulator-FoHIS/Results/With_Depth-Anything', '../Fog_Simulator-FoHIS/Results/With_MiDaS']\n",
    "all_results = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_results = process_images_in_folder(folder)\n",
    "    all_results.extend(folder_results)\n",
    "\n",
    "# Save the results\n",
    "with open('results.txt', 'w') as f:\n",
    "    for image_path, result in all_results:\n",
    "        f.write(f\"{image_path}: {result}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-09T16:57:19.026914Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_results"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
